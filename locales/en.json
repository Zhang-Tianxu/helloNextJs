{
  "site": {
    "title": "Next.js on GitHub Pages",
    "description": "Deploy your static Next.js site to GitHub Pages."
  },
  "nav": {
    "home": "Home",
    "papers": "Papers"
  },
  "paper": {
    "title": "Open-World Reinforcement Learning over Long Short-Term Imagination",
    "abstract": "Abstract",
    "evaluation": "Evaluation",
    "bibtex": "BibTeX",
    "copy": "Copy",
    "copied": "Copied!",
    "copyFailed": "Copy failed",
    "copyTitle": "Copy BibTeX",
    "copiedTitle": "Copied!",
    "links": {
      "paper": "Paper",
      "arxiv": "arXiv",
      "code": "Code",
      "slides": "Slides",
      "thread": "Thread",
      "bilibili": "bilibili"
    },
    "abstractContent": "Training visual reinforcement learning agents in a high-dimensional open world presents significant challenges. While various model-based methods have improved sample efficiency by learning interactive world models, these agents tend to be \"short-sighted\", as they are typically trained on short snippets of imagined experiences. We argue that the primary challenge in open-world decision-making is improving the exploration efficiency across a vast state space, especially for tasks that demand consideration of long-horizon payoffs. In this paper, we present LS-Imgine, which extends the imagination horizon within a limited number of state transition steps, enabling the agent to explore behaviors that potentially lead to promising long-term feedback. The foundation of our approach is to build a long short-term world model. To achieve this, we simulate goal-conditioned jumpy state transitions and compute corresponding affordance maps by zooming in on specific areas within single images. This facilitates the integration of direct long-term values into behavior learning. Our method demonstrates significant improvements over state-of-the-art techniques in MineDojo.",
    "frameworkDescription": "The general framework of LS-Imagine, an MBRL agent that operates solely on raw pixels. The fundamental idea is to extend the imagination horizon within a limited number of state transition steps, enabling the agent to explore behaviors that potentially lead to promising long-term feedback."
  },
  "language": {
    "switch": "Switch Language",
    "english": "English",
    "chinese": "中文"
  }
}